experiment_args:
  experiment_name: baseline_consep
  experiment_version: hover_zarr_minmax

dataset_args:
  train_dataset: consep         # One of (consep, pannuke, kumar, monusac)

model_args:
  architecture_design:
    module_args:
      activation: relu          # One of (relu, mish, swish)
      normalization: bn         # One of (bn, bcn, nope)
      weight_standardize: False # Weight standardization
      weight_init: he           # One of (he, eoc, fixup) (only for decoder if pretrain)
    encoder_args:
      in_channels: 3            # RGB input images
      encoder: resnet50         # https://github.com/qubvel/segmentation_models.pytorch
      pretrain: True            # Use imagenet pre-trained encoder
      encoder_depth: 5          # Number of layers in encoder
    decoder_args:
      n_blocks: 2               # Number of convolutions blocks in each decoder block
      short_skips: nope         # One of (residual, dense, nope) (for decoder branch only)
      long_skips: unet          # One of (unet, unet++, unet3+, nope)
      merge_policy: sum         # One of (sum, cat) (for long skips)
      upsampling: fixed_unpool  # One of (interp, max_unpool, transconv, fixed_unpool)

  decoder_branches:
    type: True
    aux: True
    aux_type: hover              # One of (hover, dist, contour) (ignored if aux=False)

training_args:
  normalize_input: False          # minmax normalize input images after augs (nans??)
  freeze_encoder: False          # freeze the weights in the encoder (for fine tuning)
  weight_balancing: null         # One of (gradnorm, uncertainty, null)
  augmentations:
    - hue_sat
    - non_rigid
    - blur
    - non_spatial

  optimizer_args:
    optimizer: adam              # One of https://github.com/jettify/pytorch-optimizer 
    lr: 0.0005
    encoder_lr: 0.00005
    weight_decay: 0.0003
    encoder_weight_decay: 0.00003
    lookahead: False
    bias_weight_decay: True
    scheduler_factor: 0.25
    scheduler_patience: 3

  loss_args:
    inst_branch_loss: dice_ce
    type_branch_loss: dice_ce
    aux_branch_loss: mse_ssim
    edge_weight: False         # Give penalty to nuclei borders in cross-entropy based losses
    class_weights: False       # Weight classes by the # of class pixels in the data

runtime_args:
  resume_training: False
  num_epochs: 5
  num_gpus: 1
  batch_size: 8
  model_input_size: 256       # Multiple of 32. Tuple(int, int) 
  num_workers: 8              # number workers for data loeader


