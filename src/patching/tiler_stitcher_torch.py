import torch
import torch.nn as nn 
import torch.nn.functional as F
import numpy as np
from typing import Tuple

from .viz_patches import viz_patches


class TilerStitcherTorch:
    def __init__(self,              
                 batch_shape: Tuple[int],
                 patch_shape: Tuple[int],
                 stride_size: int,
                 padding: bool=True) -> None:
        """
        Patch extractor and stitcher class. Operates on batched torch tensors.
        Input images can be given as DataLoader batches.
        
        Follows this discussion:
        https://discuss.pytorch.org/t/how-to-split-tensors-with-overlap-and-then-reconstruct-the-original-tensor/70261/12

        Args:
        ------------
            batch_shape (Tuple[int]):
                input image shape (B, C, H, W)
            patch_shape (Tuple[int]):
                Shape of a patch (H, W)
            stride_size (int):
                Stride of the sliding window
            padding (bool):
                pad the input image to a multiple of patch_shape such that 
                every part of input gets patched. Creates some redundancy.
        """
        self.ih, self.iw = batch_shape[-2:]
        self.batch_size = batch_shape[0]
        self.patch_shape = patch_shape
        self.stride_size = stride_size
        self.padding = padding

    @property
    def margins(self) -> Tuple[int]:
        """
        Returns:
        -------------
            Tuple[int]. Length of margins needed in the input image. Multiple of patch_shape
        """
        extra_pad = 200
        ph, pw = self.patch_shape[:2]
        margin_y = int(np.ceil((self.ih + extra_pad) / ph)*ph - self.ih)
        margin_x = int(np.ceil((self.iw + extra_pad) / pw)*pw - self.iw)
        return margin_y, margin_x

    def extract_patches_from_batched(self, patches: torch.Tensor) -> torch.Tensor:
        """
        Use unfold to patch a batched tensor image.

        Args:
        -------------
            patches (torch.Tensor):
                Batched input image. Shape (B, C, H, W)

        Returns:
        -------------
            patched image of shape (B, C, n_patches, patch_height, patch_width)
        """
        if self.padding:
            pad_x, pad_y = self.margins
            patches = F.pad(patches.float(), [pad_x, pad_x, pad_y, pad_y], mode="reflect")

        self.B, self.C, self.H, self.W = patches.shape
        dims = list(range(2, patches.dim()))
        for dim, patch_size in zip(dims, self.patch_shape):
            patches = patches.unfold(dim, patch_size, self.stride_size)
        
        patches = patches.contiguous().view(self.B, self.C, -1, self.patch_shape[0], self.patch_shape[1])
        return patches

    def stitch_batched_patches(self, patches: torch.Tensor, n_channels: int=3) -> torch.Tensor:
        """
        Stitch patches back to one batched image.
        Patches need to be generated by the same instances 
        extract_patches_from_batched() method

        Args:
        -------------
            patches (torch.Tensor):
                input image in patches of shape (B, C, n_patches, H, W).
            n_channels (int, default=3):
                Number of channels in the output. 

        Returns:
        -------------
             torch.Tensor (image) of shape (B, C, H, W) 
        """
        _, C, _, ph, pw = patches.shape
        ph, pw = self.patch_shape[:2]
        patches = patches.float().contiguous().view(self.B, C, -1, ph*pw)
        patches = patches.permute(0, 1, 3, 2) 

        patches = patches.contiguous().view(self.B, C*ph*pw, -1)
        output = F.fold(patches, output_size=(self.H, self.W), kernel_size=ph, stride=self.stride_size)

        recovery_mask = F.fold(torch.ones_like(patches), output_size=(self.H, self.W), kernel_size=ph, stride=self.stride_size)
        output = output/recovery_mask

        if self.padding:
            pad_x, pad_y = self.margins
            output = output[:, :, pad_y:-pad_y, pad_x:-pad_x]
        
        return output

    @staticmethod
    def vizualize(patches: np.ndarray) -> Tuple[int]:
        """
        Convert first to numpy and visualize one batch per time
        if you dont want this to crash

        Conversion example:
        -------------------
            patches = (patches[1, ...].permute(0, 2, 3, 1).numpy().astype("uint8")

        """
        viz_patches(patches)