{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leos/.local/lib/python3.6/site-packages/pandas/compat/_optional.py:106: UserWarning: Pandas requires version '1.2.1' or newer of 'bottleneck' (version '1.2.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "from functools import partial\n",
    "from omegaconf import OmegaConf\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.logging import TestTubeLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.utilities.cloud_io import load as pl_load\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler, PopulationBasedTraining\n",
    "from src.dl.lightning_model import SegModel\n",
    "from src.conf.conf_schema import Schema\n",
    "from src.conf.config import CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuneReportCallback(Callback):\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        tune.report(\n",
    "            loss=trainer.callback_metrics[\"avg_val_loss\"].item(),\n",
    "            mean_accuracy=trainer.callback_metrics[\"avg_val_accuracy\"].item())\n",
    "\n",
    "\n",
    "class CheckpointCallback(Callback):\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        with tune.checkpoint_dir(step=trainer.global_step) as checkpoint_dir:\n",
    "            trainer.save_checkpoint(os.path.join(checkpoint_dir, \"checkpoint\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = pl_load(lightning_model.fm.model_checkpoint(\"last\").as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightning_model._load_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.current_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = CONFIG\n",
    "\n",
    "def train_tune_checkpoint(\n",
    "    training_args,\n",
    "    dataset_args,\n",
    "    experiment_args,\n",
    "    checkpoint_dir=None,\n",
    "    num_epochs=10,\n",
    "    num_gpus=0):\n",
    "    \n",
    "    tt_logger = TestTubeLogger(\n",
    "        save_dir=tune.get_trial_dir(),\n",
    "        name=config.experiment_args.model_name,\n",
    "        version=config.experiment_args.experiment_version\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        default_root_dir=config.experiment_args.experiment_root_dir,\n",
    "        max_epochs=config.training_args.num_epochs,\n",
    "        gpus=config.training_args.num_gpus,  \n",
    "        logger=tt_logger,\n",
    "        progress_bar_refresh_rate=0,\n",
    "        callbacks=[CheckpointCallback(), TuneReportCallback()],\n",
    "        profiler=True\n",
    "    )\n",
    "    \n",
    "    # Get the model from checkpoint or from 0\n",
    "    if checkpoint_dir:\n",
    "        base_model = smp.Unet(\n",
    "            encoder_name=\"resnext50_32x4d\", \n",
    "            classes=2\n",
    "        )\n",
    "        \n",
    "        pl_model = SegModel(\n",
    "            base_model, \n",
    "            config.dataset_args,\n",
    "            config.experiment_args,\n",
    "            config.training_args\n",
    "        )\n",
    "        \n",
    "        # get the ckpt\n",
    "        checkpoint = pl_load(checkpoint_dir, map_location=lambda storage, loc: storage)\n",
    "        #checkpoint = torch.load(checkpoint_dir, map_location = lambda storage, loc : storage)\n",
    "        pl_model.load_state_dict(checkpoint['state_dict'])\n",
    "        trainer.current_epoch = checkpoint[\"epoch\"]\n",
    "    else:\n",
    "        base_model = smp.Unet(\n",
    "            encoder_name=\"resnext50_32x4d\", \n",
    "            classes=2\n",
    "        )\n",
    "        \n",
    "        pl_model = SegModel(\n",
    "            base_model, \n",
    "            config.dataset_args,\n",
    "            config.experiment_args,\n",
    "            config.training_args\n",
    "        )\n",
    "\n",
    "\n",
    "    trainer.fit(pl_model)\n",
    "    \n",
    "#train_tune_checkpoint(\n",
    "#    config.dataset_args,\n",
    "#    config.experiment_args,\n",
    "#    config.training_args,\n",
    "#    checkpoint_dir=\"/home/leos/Dippa/results/tests/Unet/version_test_pannuke_unet2/epoch=6.ckpt\",\n",
    "#    data_dir=\"/home/leos/Dippa/patches/hdf5/pannuke/patch256_train_pannuke.pytable\",\n",
    "#    num_epochs=10,\n",
    "#    num_gpus=1\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<function train_tune_checkpoint at 0x7fd62258b840>, dataset_args={'dataset': 'kumar', 'class_types': 'binary', 'patches_dtype': 'hdf5', 'hdf5_patches_root_dir': '/home/local/leos/Dippa_test/patches/hdf5', 'npy_patches_root_dir': '/home/local/leos/Dippa_test/patches/npy', 'phases': ['train', 'valid', 'test'], 'tissues': []}, experiment_args={'model_name': 'Unet', 'experiment_version': 'test_pannuke_unet2', 'experiment_root_dir': '/home/local/leos/Dippa_test/results/tests'}, num_epochs=7, num_gpus=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus_per_trial=1\n",
    "partial(\n",
    "    train_tune_checkpoint,\n",
    "    dataset_args=config.dataset_args,\n",
    "    experiment_args=config.experiment_args,\n",
    "    num_epochs=config.training_args.num_epochs,\n",
    "    num_gpus=gpus_per_trial\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_pbt(\n",
    "    config, \n",
    "    num_samples=10, \n",
    "    num_epochs=10, \n",
    "    gpus_per_trial=1) -> None:\n",
    "    \n",
    "    tune.register_trainable('train_tune_checkpoint', train_tune_checkpoint)\n",
    "    \n",
    "    # import sys\n",
    "    # print(sys.path)\n",
    "    train_config = {\n",
    "        \"edge_weight\":1,\n",
    "        \"lr\": 1e-3,\n",
    "        \"batch_size\": 6,\n",
    "    }\n",
    "\n",
    "    scheduler = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        perturbation_interval=4,\n",
    "        hyperparam_mutations={\n",
    "            \"lr\": lambda: tune.loguniform(1e-4, 1e-1).func(None),\n",
    "            \"batch_size\": [4, 8, 16],\n",
    "            \"edge_weight\":[1.1, 1.2, 1.5, 2]\n",
    "        })\n",
    "\n",
    "    reporter = CLIReporter(\n",
    "        parameter_columns=[\"edge_weight\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"mean_accuracy\", \"training_iteration\"]\n",
    "    )\n",
    "\n",
    "    tune.run(\n",
    "        partial(\n",
    "            train_tune_checkpoint,\n",
    "            dataset_args=config.dataset_args,\n",
    "            experiment_args=config.experiment_args,\n",
    "            num_epochs=num_epochs,\n",
    "            num_gpus=gpus_per_trial\n",
    "        ),\n",
    "        resources_per_trial={\"cpu\": 1, \"gpu\": gpus_per_trial},\n",
    "        config=train_config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter,\n",
    "        name=\"tune_pbt\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leos/.local/lib/python3.6/site-packages/ray/resource_spec.py:310: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/proc/driver/nvidia/gpus/0000:01:00.0/information' mode='r' encoding='UTF-8'>\n",
      "\n",
      "2020-09-23 19:05:47,466\tINFO resource_spec.py:231 -- Starting Ray with 14.4 GiB memory available for workers and up to 7.22 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:746: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/redis-shard_0.err' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:746: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/redis-shard_0.out' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:746: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/redis.err' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:746: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/redis.out' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:748: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/gcs_server.out' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:748: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/gcs_server.err' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:750: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/monitor.out' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:750: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/monitor.err' mode='a' encoding='utf-8'>\n",
      "\n",
      "2020-09-23 19:05:48,009\tINFO services.py:1193 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:755: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/dashboard.out' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:755: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/dashboard.err' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:763: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/plasma_store.out' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:763: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/plasma_store.err' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:764: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/raylet.out' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:764: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/raylet.err' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:765: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/reporter.out' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:765: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/reporter.err' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:768: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/log_monitor.out' mode='a' encoding='utf-8'>\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ray/node.py:768: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/log_monitor.err' mode='a' encoding='utf-8'>\n",
      "\n",
      "2020-09-23 19:05:48,230\tWARNING experiment.py:215 -- No name detected on trainable. Using DEFAULT.\n",
      "2020-09-23 19:05:48,231\tWARNING registry.py:64 -- Detected unknown callable for trainable. Converting to class.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 8.4/31.2 GiB\n",
      "PopulationBasedTraining: 0 checkpoints, 0 perturbs\n",
      "Resources requested: 1/12 CPUs, 1/1 GPUs, 0.0/14.4 GiB heap, 0.0/4.98 GiB objects (0/1.0 GPUType:RTX)\n",
      "Result logdir: /home/leos/ray_results/tune_pbt\n",
      "Number of trials: 1 (1 RUNNING)\n",
      "+---------------------+----------+-------+---------------+-------+--------------+\n",
      "| Trial name          | status   | loc   |   edge_weight |    lr |   batch_size |\n",
      "|---------------------+----------+-------+---------------+-------+--------------|\n",
      "| DEFAULT_a5081_00000 | RUNNING  |       |             1 | 0.001 |            6 |\n",
      "+---------------------+----------+-------+---------------+-------+--------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m /home/leos/.local/lib/python3.6/site-packages/pandas/compat/_optional.py:106: UserWarning: Pandas requires version '1.2.1' or newer of 'bottleneck' (version '1.2.0' currently installed).\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m   warnings.warn(msg, UserWarning)\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m /usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m /usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m /usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m /usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m /usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m /usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m /usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m /home/leos/.local/lib/python3.6/site-packages/ray/worker.py:959: ResourceWarning:\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/worker-83dfe1035acebb0bd5a49aea7828dd4344f2b3a8-0100.out' mode='a' encoding='utf-8'>\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m /home/leos/.local/lib/python3.6/site-packages/ray/worker.py:963: ResourceWarning:\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m unclosed file <_io.TextIOWrapper name='/tmp/ray/session_2020-09-23_19-05-47_464850_16710/logs/worker-83dfe1035acebb0bd5a49aea7828dd4344f2b3a8-0100.err' mode='a' encoding='utf-8'>\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m GPU available: True, used: True\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m TPU available: False, using: 0 TPU cores\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m ['/home/leos/.local/lib/python3.6/site-packages/git/ext/gitdb', '/home/leos/.local/lib/python3.6/site-packages/ray/thirdparty_files', '/home/local/leos/Dippa_test/notebooks', '/home/leos/.local/lib/python3.6/site-packages', '/home/leos/.local/lib/python3.6/site-packages/ray/pickle5_files', '/home/local/leos/.local/lib/python3.6/site-packages/ray/workers', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/home/leos/.local/lib/python3.6/site-packages', '/home/local/leos/Dippa_test', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/home/leos/.local/lib/python3.6/site-packages/IPython/extensions', '/home/leos/.local/lib/python3.6/site-packages/gitdb/ext/smmap']\n",
      "Validation sanity check: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m   | Name  | Type             | Params\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m -------------------------------------------\n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m 0 | model | Unet             | 31 M  \n",
      "\u001b[2m\u001b[36m(pid=16786)\u001b[0m 1 | CE    | CrossEntropyLoss | 0     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]\n",
      "Validation sanity check: 100%|██████████| 2/2 [00:03<00:00,  2.01s/it]\n",
      "Epoch 1:   0%|          | 0/845 [00:00<?, ?it/s]                      \n",
      "Epoch 1:   0%|          | 1/845 [00:03<46:18,  3.29s/it, loss=0.860, v_num=test_pannuke_unet2, train_loss=0.86]\n",
      "Epoch 1:   0%|          | 2/845 [00:04<28:09,  2.00s/it, loss=0.865, v_num=test_pannuke_unet2, train_loss=0.871]\n",
      "Epoch 1:   0%|          | 3/845 [00:04<22:09,  1.58s/it, loss=0.862, v_num=test_pannuke_unet2, train_loss=0.856]\n",
      "Epoch 1:   0%|          | 4/845 [00:06<23:05,  1.65s/it, loss=0.869, v_num=test_pannuke_unet2, train_loss=0.888]\n",
      "Epoch 1:   1%|          | 5/845 [00:07<20:19,  1.45s/it, loss=0.875, v_num=test_pannuke_unet2, train_loss=0.899]\n",
      "Epoch 1:   1%|          | 6/845 [00:07<18:29,  1.32s/it, loss=0.875, v_num=test_pannuke_unet2, train_loss=0.874]\n",
      "Epoch 1:   1%|          | 7/845 [00:08<16:55,  1.21s/it, loss=0.874, v_num=test_pannuke_unet2, train_loss=0.873]\n",
      "Epoch 1:   1%|          | 8/845 [00:08<15:38,  1.12s/it, loss=0.872, v_num=test_pannuke_unet2, train_loss=0.852]\n",
      "Epoch 1:   1%|          | 9/845 [00:09<14:57,  1.07s/it, loss=0.867, v_num=test_pannuke_unet2, train_loss=0.829]\n",
      "Epoch 1:   1%|          | 10/845 [00:10<14:24,  1.04s/it, loss=0.863, v_num=test_pannuke_unet2, train_loss=0.831]\n",
      "Epoch 1:   1%|▏         | 11/845 [00:11<14:01,  1.01s/it, loss=0.860, v_num=test_pannuke_unet2, train_loss=0.828]\n",
      "Epoch 1:   1%|▏         | 12/845 [00:11<13:25,  1.03it/s, loss=0.859, v_num=test_pannuke_unet2, train_loss=0.843]\n",
      "Epoch 1:   2%|▏         | 13/845 [00:12<12:50,  1.08it/s, loss=0.857, v_num=test_pannuke_unet2, train_loss=0.835]\n",
      "Epoch 1:   2%|▏         | 14/845 [00:12<12:21,  1.12it/s, loss=0.854, v_num=test_pannuke_unet2, train_loss=0.823]\n",
      "Epoch 1:   2%|▏         | 15/845 [00:13<12:02,  1.15it/s, loss=0.852, v_num=test_pannuke_unet2, train_loss=0.817]\n",
      "Epoch 1:   2%|▏         | 16/845 [00:13<11:48,  1.17it/s, loss=0.849, v_num=test_pannuke_unet2, train_loss=0.803]\n",
      "Epoch 1:   2%|▏         | 17/845 [00:14<11:34,  1.19it/s, loss=0.847, v_num=test_pannuke_unet2, train_loss=0.823]\n",
      "Epoch 1:   2%|▏         | 18/845 [00:14<11:19,  1.22it/s, loss=0.845, v_num=test_pannuke_unet2, train_loss=0.801]\n",
      "Epoch 1:   2%|▏         | 19/845 [00:15<11:05,  1.24it/s, loss=0.842, v_num=test_pannuke_unet2, train_loss=0.789]\n",
      "Epoch 1:   2%|▏         | 20/845 [00:15<10:52,  1.26it/s, loss=0.839, v_num=test_pannuke_unet2, train_loss=0.785]\n",
      "Epoch 1:   2%|▏         | 21/845 [00:16<10:44,  1.28it/s, loss=0.834, v_num=test_pannuke_unet2, train_loss=0.769]\n",
      "Epoch 1:   3%|▎         | 22/845 [00:16<10:32,  1.30it/s, loss=0.830, v_num=test_pannuke_unet2, train_loss=0.78] \n",
      "Epoch 1:   3%|▎         | 23/845 [00:17<10:21,  1.32it/s, loss=0.826, v_num=test_pannuke_unet2, train_loss=0.781]\n",
      "Epoch 1:   3%|▎         | 24/845 [00:17<10:13,  1.34it/s, loss=0.820, v_num=test_pannuke_unet2, train_loss=0.766]\n",
      "Epoch 1:   3%|▎         | 25/845 [00:18<10:02,  1.36it/s, loss=0.813, v_num=test_pannuke_unet2, train_loss=0.755]\n",
      "Epoch 1:   3%|▎         | 26/845 [00:18<09:53,  1.38it/s, loss=0.806, v_num=test_pannuke_unet2, train_loss=0.741]\n",
      "Epoch 1:   3%|▎         | 27/845 [00:19<09:45,  1.40it/s, loss=0.800, v_num=test_pannuke_unet2, train_loss=0.741]\n",
      "Epoch 1:   3%|▎         | 28/845 [00:19<09:38,  1.41it/s, loss=0.794, v_num=test_pannuke_unet2, train_loss=0.747]\n",
      "Epoch 1:   3%|▎         | 29/845 [00:20<09:34,  1.42it/s, loss=0.790, v_num=test_pannuke_unet2, train_loss=0.733]\n",
      "Epoch 1:   4%|▎         | 30/845 [00:20<09:28,  1.43it/s, loss=0.783, v_num=test_pannuke_unet2, train_loss=0.703]\n",
      "Epoch 1:   4%|▎         | 31/845 [00:21<09:22,  1.45it/s, loss=0.778, v_num=test_pannuke_unet2, train_loss=0.723]\n",
      "Epoch 1:   4%|▍         | 32/845 [00:21<09:17,  1.46it/s, loss=0.771, v_num=test_pannuke_unet2, train_loss=0.714]\n",
      "Epoch 1:   4%|▍         | 33/845 [00:22<09:10,  1.47it/s, loss=0.766, v_num=test_pannuke_unet2, train_loss=0.725]\n"
     ]
    }
   ],
   "source": [
    "tune_pbt(config, num_samples=1, num_epochs=1, gpus_per_trial=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
