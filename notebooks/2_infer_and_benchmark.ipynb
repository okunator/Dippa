{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dl.inference.inferer import Inferer\n",
    "import src.dl.lightning as lightning\n",
    "from src.data import PannukeDataModule, ConsepDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Inference\n",
    "\n",
    "## Param info of the Inferer class\n",
    "\n",
    "- `stride_size` has a big impact on results. The smaller it is, the better the accuracy. However, small size results in increased memory footprint and running times\n",
    "- `apply_weights=True` results in giving less weight on the tile boundaries during forward passes preventing boundary artifacts in the predictions. Used only for the auxilliary branch predictions because this is where the boundary effects affect the most (especially in horizontal and vertical gradient predictions)\n",
    "- By tweaking `*batch_size` and `loader_num_workers` params, you can boost the inference performance depending on your machine. Hitting the sweetspot requires a few runs and a good knowledge of your machine specs.\n",
    "- If your `in_dir` contains hundreds of images, use `n_images={int}` to refresh memory after every `n_images` are processed. This is needed because the Inferer class typically saves all the intermediate results in memory to be able to perform benchmarking etc. However, if you just need to do inference for a big number of images and no need for benchmarking, this will help.\n",
    "- If you want to segment a wsi which contains many redundant tissue sections you can set `auto_range=True`. However, this only works if your `in_dir` contains images that are extracted from the same wsi and contain x- and y-coordinates encoded in their filenames. This will filter out only the tile files that are contained in the first tissue section of the wsi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the inferer\n",
    "in_dir = \"/path/to/images/\"\n",
    "gt_dir = None # This is optional. Can be None\n",
    "exp_name = \"panoptic\" # name of the experiment (directory)\n",
    "exp_version = \"effnetv2\" # name of the experiment version (sub directory inside the experiment dir)\n",
    "lightning_model = lightning.SegModel.from_experiment(name=exp_name, version=exp_version)\n",
    "\n",
    "inferer = Inferer(\n",
    "    lightning_model,\n",
    "    in_data_dir=in_dir,\n",
    "    gt_mask_dir=gt_dir,\n",
    "    patch_size=(256, 256),\n",
    "    stride_size=80,\n",
    "    fn_pattern=\"*\",\n",
    "    model_weights=\"last\",\n",
    "    apply_weights=True,\n",
    "    post_proc_method=\"cellpose\",\n",
    "    loader_batch_size=1,\n",
    "    loader_num_workers=1,\n",
    "    model_batch_size=16,\n",
    "    auto_range=True,\n",
    "    n_images=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference for ['x-66000_y-87000']: 100%|██████████| 32/32 [03:16<00:00,  6.13s/batch, patches=289/289]\n",
      "Post-processing: 100%|██████████| 32/32 [00:39<00:00,  1.24s/it]\n",
      "Running inference for ['x-68000_y-96000']: 100%|██████████| 32/32 [03:22<00:00,  6.32s/batch, patches=289/289]\n",
      "Post-processing: 100%|██████████| 32/32 [00:50<00:00,  1.58s/it]\n",
      "Running inference for ['x-71000_y-94000']: 100%|██████████| 32/32 [03:14<00:00,  6.07s/batch, patches=289/289]\n",
      "Post-processing: 100%|██████████| 32/32 [00:36<00:00,  1.15s/it]\n",
      "Running inference for ['x-83000_y-94000']: 100%|██████████| 32/32 [03:21<00:00,  6.30s/batch, patches=289/289]\n",
      "Post-processing: 100%|██████████| 32/32 [00:47<00:00,  1.49s/it]\n",
      "Running inference for ['x-85000_y-90000']: 100%|██████████| 32/32 [03:25<00:00,  6.43s/batch, patches=289/289]\n",
      "Post-processing: 100%|██████████| 32/32 [01:03<00:00,  1.97s/it]\n",
      "Running inference for ['x-87000_y-102000']: 100%|██████████| 32/32 [03:52<00:00,  7.26s/batch, patches=289/289]\n",
      "Post-processing: 100%|██████████| 32/32 [01:04<00:00,  2.03s/it]\n",
      "Running inference for ['x-88000_y-93000']: 100%|██████████| 32/32 [03:36<00:00,  6.76s/batch, patches=289/289]\n",
      "Post-processing: 100%|██████████| 32/32 [01:00<00:00,  1.89s/it]\n",
      "Running inference for ['x-90000_y-86000']: 100%|██████████| 32/32 [03:50<00:00,  7.20s/batch, patches=289/289]\n",
      "Post-processing: 100%|██████████| 32/32 [00:58<00:00,  1.84s/it]\n",
      "Running inference for ['x-92000_y-89000']: 100%|██████████| 24/24 [02:26<00:00,  6.09s/batch, patches=289/289]\n",
      "Post-processing: 100%|██████████| 24/24 [00:33<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "area_classes = {\n",
    "    \"background\": 0,\n",
    "    \"areastroma\": 1,\n",
    "    \"area_cin\": 2,\n",
    "    \"areasquam\": 3,\n",
    "    \"areagland\": 4,\n",
    "}\n",
    "\n",
    "cell_classes = {\n",
    "    \"background\": 0,\n",
    "    \"neoplastic\": 1,\n",
    "    \"inflammatory\": 2,\n",
    "    \"connective\": 3,\n",
    "    \"dead\": 4,\n",
    "    \"glandular_epithel\": 5,\n",
    "    \"squamous_epithel\": 6\n",
    "}\n",
    "\n",
    "result_dir = \"/path/to/results/geojson\"\n",
    "\n",
    "inferer.run_inference(\n",
    "    save_dir=result_dir,\n",
    "    fformat=\"geojson\",\n",
    "    offsets=True,\n",
    "    classes_sem=area_classes,\n",
    "    classes_type=cell_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the tile predictions\n",
    "\n",
    "- You can plot the intermediate results of the segmentation model in the cell below.\n",
    "- This works only if `n_images=None` in the Inferer class. Otherwise the intermediate results are cleared from the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from skimage.color import label2rgb\n",
    "# from src.utils import FileHandler\n",
    "# from pathlib import Path\n",
    "# from src.utils import draw_thing_contours, draw_stuff_contours, label_sem_map,\n",
    "\n",
    "# ix = 5\n",
    "# keys = list(inferer.soft_insts.keys())\n",
    "# key = keys[ix]\n",
    "# img = FileHandler.read_img([f for f in sorted(Path(inferer.in_data_dir).glob(\"*\")) if key in f.name][0])\n",
    "# areas = draw_stuff_contours(label_sem_map(inferer.sem_maps[key]), img, inferer.sem_maps[key], classes=area_classes, thickness=5, fill_contours=True)\n",
    "# everything = draw_thing_contours(inferer.inst_maps[key], areas, inferer.type_maps[key], classes=cell_classes)\n",
    "\n",
    "# fig, ax = plt.subplots(2, 2, figsize=(40, 40))\n",
    "# ax = ax.flatten()\n",
    "# ax[0].imshow(label2rgb(inferer.sem_maps[key], bg_label=0))\n",
    "# ax[1].imshow(label2rgb(inferer.type_maps[key], bg_label=0))\n",
    "# ax[2].imshow(img)\n",
    "# ax[3].imshow(everything)\n",
    "# # ax[2].imshow(label2rgb(FileHandler.read_mask([f for f in inferer.gt_mask_dir if key in f.name][0], \"inst_map\"), bg_label=0))\n",
    "# # ax[3].imshow(label2rgb(FileHandler.read_mask([f for f in inferer.gt_mask_dir if key in f.name][0], \"type_map\"), bg_label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging results\n",
    "\n",
    "- If you saved the result predictions to geojson format and all the input tiles are adjascent to each other (e.g. extracted from a WSI), you can merge all the tiles together to form a QuPath readable geojson file.\n",
    "- Only requirement for merging the tiles is that the x- and -y coordinates are encoded in the filenames of the images in `in_dir`\n",
    "- You can plot the merged results in the second cell below this to check if everything went correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import CellMerger, AreaMerger\n",
    "\n",
    "# Merge cell annotations\n",
    "in_dir_cells = \"/path/to/geojson/cells\"\n",
    "fname_cells = \"path/to/my_wsi_cells.json\"\n",
    "\n",
    "c = CellMerger(in_dir=in_dir_cells)\n",
    "c.merge(fname=fname_cells)\n",
    "\n",
    "\n",
    "# If the netowork outputs area predictions u can merge them too. If not, comment this out\n",
    "in_dir_areas = \"/path/to/geojson/areas\"\n",
    "fname_areas = \"path/to/my_wsi_areas.json\"\n",
    "\n",
    "a = AreaMerger(in_dir=in_dir_areas)\n",
    "a.merge(fname=fname_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import GSONTile\n",
    "\n",
    "# Plot the results\n",
    "cells = GSONTile(fname_cells)\n",
    "areas = GSONTile(fname_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Benchmarking\n",
    "\n",
    "- Only works if `gt_mask_dir` is provided in the Inferer class.\n",
    "- The first cell below this one runs binary metrics i.e. segmentation metrics for all cells.\n",
    "- The second cell below this one runs metrics per cell type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_list = None\n",
    "binary_scores = inferer.benchmark_insts(pattern_list=pattern_list, file_prefix=f\"{exp_name}_{exp_version}\")\n",
    "binary_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_list = None\n",
    "type_scores = inferer.benchmark_types(\n",
    "    classes=PannukeDataModule.get_classes(),\n",
    "    pattern_list=pattern_list, \n",
    "    file_prefix=f\"{exp_version}\"\n",
    ")\n",
    "type_scores = type_scores[type_scores.index.str.contains(\"avg\")]\n",
    "type_scores"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d257930f390edd16081c76357b57cbbee027806f72e6af695a5873c4aff6357"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('DippaEnv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "3ea01dde592f11f139bb8a18f7472b919436c8f8399691d376fd4b0010891aeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
