{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/torchvision/extension.py:11: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.BufferedReader name='/home/leos/.local/lib/python3.6/site-packages/torchvision/_C.so'>\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint #GpuUsageLogger\n",
    "from src.settings import RESULT_DIR\n",
    "from src.conf.config import CONFIG\n",
    "from src.dl.lightning_model import SegModel, plot_metrics\n",
    "from src.dl.model_builder import ModelBuilder\n",
    "from src.dl.loss_builder import LossBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a pytorch model\n",
    "\n",
    "- Any model should work if it's wrapped to lightning SegModel wrapper. e.g. smp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the config file\n",
    "config = CONFIG\n",
    "\n",
    "# Set the model to do instance or panoptic segmentation (depends what's in the config.py file)\n",
    "base_model = ModelBuilder.set_model(\"Unet\", config)\n",
    "\n",
    "# Insert the model to pytorch lightning framework. (Simplifies the training and other stuff)\n",
    "lightning_model = SegModel.from_conf(base_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/leos/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning:\n",
      "\n",
      "Checkpoint directory /home/local/leos/Dippa/results/tests/UNET/version_panoptic_DICEloss_test_edge_w10 exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "tt_logger = pl_loggers.TestTubeLogger(\n",
    "    save_dir=RESULT_DIR,\n",
    "    name=config.experiment_args.model_name,\n",
    "    version=config.experiment_args.experiment_version\n",
    ")\n",
    "\n",
    "checkpoint_dir = (\n",
    "    Path(tt_logger.save_dir)\n",
    "    / tt_logger.experiment.name\n",
    "    / f\"version_{tt_logger.experiment.version}\"\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath = str(checkpoint_dir),\n",
    "    save_top_k = 1,\n",
    "    save_last = True,\n",
    "    verbose = True, \n",
    "    monitor = 'avg_val_loss',\n",
    "    mode = 'min',\n",
    "    prefix = ''\n",
    ")\n",
    "\n",
    "if config.training_args.resume_training:   \n",
    "    last_checkpoint_path = lightning_model.fm.model_checkpoint(\"last\")\n",
    "    trainer = Trainer(\n",
    "        default_root_dir=config.experiment_args.experiment_root_dir,\n",
    "        max_epochs=config.training_args.num_epochs, \n",
    "        gpus=config.training_args.num_gpus,  \n",
    "        logger=tt_logger,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        #callbacks=[GPUStatsMonitor()],\n",
    "        resume_from_checkpoint=str(last_checkpoint_path),\n",
    "        profiler=True,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    trainer = Trainer(\n",
    "        default_root_dir=config.experiment_args.experiment_root_dir,\n",
    "        max_epochs=config.training_args.num_epochs, \n",
    "        gpus=config.training_args.num_gpus,  \n",
    "        logger=tt_logger,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        # callbacks=[GpuUsageLogger()],\n",
    "        profiler=True,\n",
    "    )\n",
    "    \n",
    "\n",
    "# find the batch size automatically\n",
    "# new_batch_size = trainer.scale_batch_size(lightning_model)\n",
    "\n",
    "# Override old batch size\n",
    "# lightning_model.batch_size = new_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = (\n",
    "    Path(tt_logger.save_dir)\n",
    "    / tt_logger.experiment.name\n",
    "    / f\"version_{tt_logger.experiment.version}\"\n",
    "    / \"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "ERROR: Could not find `tensorboard`. Please ensure that your PATH\ncontains an executable `tensorboard` program, or explicitly specify\nthe path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\nenvironment variable."
     },
     "metadata": {}
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ".359, v_num=_w10]\n",
      "Validating:  76%|███████▋  | 29/38 [00:11<00:03,  2.96it/s]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 792/799 [04:49<00:02,  2.74it/s, loss=0.359, v_num=_w10]\n",
      "Epoch 2: 100%|█████████▉| 796/799 [04:50<00:01,  2.74it/s, loss=0.359, v_num=_w10]\n",
      "Validating:  97%|█████████▋| 37/38 [00:13<00:00,  3.61it/s]\u001b[A\n",
      "Epoch 00002: avg_val_loss reached 0.38360 (best 0.38360), saving model to /home/local/leos/Dippa/results/tests/UNET/version_panoptic_DICEloss_test_edge_w10/epoch=2.ckpt as top 1\n",
      "Epoch 2: 100%|██████████| 799/799 [04:52<00:00,  2.73it/s, loss=0.359, v_num=_w10]\n",
      "Epoch 3:  95%|█████████▌| 761/799 [04:40<00:14,  2.71it/s, loss=0.278, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:03<02:22,  3.84s/it]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 764/799 [04:44<00:13,  2.68it/s, loss=0.278, v_num=_w10]\n",
      "Validating:  11%|█         | 4/38 [00:04<01:07,  1.98s/it]\u001b[A\n",
      "Validating:  16%|█▌        | 6/38 [00:04<00:45,  1.43s/it]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 768/799 [04:46<00:11,  2.68it/s, loss=0.278, v_num=_w10]\n",
      "Epoch 3:  97%|█████████▋| 772/799 [04:47<00:10,  2.68it/s, loss=0.278, v_num=_w10]\n",
      "Epoch 3:  97%|█████████▋| 776/799 [04:50<00:08,  2.67it/s, loss=0.278, v_num=_w10]\n",
      "Validating:  42%|████▏     | 16/38 [00:09<00:15,  1.45it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 780/799 [04:50<00:07,  2.69it/s, loss=0.278, v_num=_w10]\n",
      "Validating:  53%|█████▎    | 20/38 [00:10<00:09,  1.90it/s]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 784/799 [04:51<00:05,  2.69it/s, loss=0.278, v_num=_w10]\n",
      "Epoch 3:  99%|█████████▊| 788/799 [04:52<00:04,  2.70it/s, loss=0.278, v_num=_w10]\n",
      "Epoch 3:  99%|█████████▉| 792/799 [04:52<00:02,  2.71it/s, loss=0.278, v_num=_w10]\n",
      "Validating:  84%|████████▍ | 32/38 [00:11<00:01,  4.99it/s]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 796/799 [04:53<00:01,  2.71it/s, loss=0.278, v_num=_w10]\n",
      "Validating:  97%|█████████▋| 37/38 [00:13<00:00,  3.94it/s]\u001b[A\n",
      "Epoch 00003: avg_val_loss  was not in top 1\n",
      "Epoch 3: 100%|██████████| 799/799 [04:55<00:00,  2.71it/s, loss=0.278, v_num=_w10]\n",
      "Epoch 4:  95%|█████████▌| 761/799 [04:44<00:14,  2.68it/s, loss=0.236, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 764/799 [04:49<00:13,  2.64it/s, loss=0.236, v_num=_w10]\n",
      "Validating:  11%|█         | 4/38 [00:04<01:51,  3.29s/it]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 768/799 [04:49<00:11,  2.65it/s, loss=0.236, v_num=_w10]\n",
      "Validating:  21%|██        | 8/38 [00:05<00:49,  1.66s/it]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 772/799 [04:51<00:10,  2.65it/s, loss=0.236, v_num=_w10]\n",
      "Validating:  32%|███▏      | 12/38 [00:09<00:37,  1.46s/it]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 776/799 [04:54<00:08,  2.64it/s, loss=0.236, v_num=_w10]\n",
      "Validating:  45%|████▍     | 17/38 [00:09<00:17,  1.18it/s]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 780/799 [04:54<00:07,  2.65it/s, loss=0.236, v_num=_w10]\n",
      "Epoch 4:  98%|█████████▊| 784/799 [04:55<00:05,  2.65it/s, loss=0.236, v_num=_w10]\n",
      "Validating:  66%|██████▌   | 25/38 [00:11<00:05,  2.23it/s]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 788/799 [04:55<00:04,  2.66it/s, loss=0.236, v_num=_w10]\n",
      "Epoch 4:  99%|█████████▉| 792/799 [04:56<00:02,  2.67it/s, loss=0.236, v_num=_w10]\n",
      "Epoch 4: 100%|█████████▉| 796/799 [04:57<00:01,  2.67it/s, loss=0.236, v_num=_w10]\n",
      "Validating:  97%|█████████▋| 37/38 [00:13<00:00,  4.44it/s]\u001b[A\n",
      "Epoch 00004: avg_val_loss  was not in top 1\n",
      "Epoch 4: 100%|██████████| 799/799 [04:58<00:00,  2.67it/s, loss=0.236, v_num=_w10]\n",
      "Epoch 5:  95%|█████████▌| 761/799 [04:54<00:14,  2.58it/s, loss=0.255, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 764/799 [04:59<00:13,  2.55it/s, loss=0.255, v_num=_w10]\n",
      "Validating:  11%|█         | 4/38 [00:04<01:52,  3.32s/it]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 768/799 [04:59<00:12,  2.56it/s, loss=0.255, v_num=_w10]\n",
      "Epoch 5:  97%|█████████▋| 772/799 [05:01<00:10,  2.56it/s, loss=0.255, v_num=_w10]\n",
      "Validating:  32%|███▏      | 12/38 [00:09<00:40,  1.56s/it]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 776/799 [05:04<00:09,  2.55it/s, loss=0.255, v_num=_w10]\n",
      "Validating:  45%|████▍     | 17/38 [00:10<00:21,  1.04s/it]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 780/799 [05:05<00:07,  2.56it/s, loss=0.255, v_num=_w10]\n",
      "Epoch 5:  98%|█████████▊| 784/799 [05:06<00:05,  2.56it/s, loss=0.255, v_num=_w10]\n",
      "Validating:  63%|██████▎   | 24/38 [00:12<00:07,  1.87it/s]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 788/799 [05:06<00:04,  2.57it/s, loss=0.255, v_num=_w10]\n",
      "Epoch 5:  99%|█████████▉| 792/799 [05:07<00:02,  2.58it/s, loss=0.255, v_num=_w10]\n",
      "Epoch 5: 100%|█████████▉| 796/799 [05:08<00:01,  2.58it/s, loss=0.255, v_num=_w10]\n",
      "Validating:  97%|█████████▋| 37/38 [00:13<00:00,  4.18it/s]\u001b[A\n",
      "Epoch 00005: avg_val_loss reached 0.36337 (best 0.36337), saving model to /home/local/leos/Dippa/results/tests/UNET/version_panoptic_DICEloss_test_edge_w10/epoch=5.ckpt as top 1\n",
      "Epoch 5: 100%|██████████| 799/799 [05:10<00:00,  2.57it/s, loss=0.255, v_num=_w10]\n",
      "Epoch 6:  95%|█████████▌| 761/799 [04:52<00:14,  2.60it/s, loss=0.248, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:04<02:35,  4.20s/it]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 764/799 [04:56<00:13,  2.57it/s, loss=0.248, v_num=_w10]\n",
      "Validating:  13%|█▎        | 5/38 [00:04<01:08,  2.09s/it]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 768/799 [04:56<00:11,  2.59it/s, loss=0.248, v_num=_w10]\n",
      "Epoch 6:  97%|█████████▋| 772/799 [04:59<00:10,  2.58it/s, loss=0.248, v_num=_w10]\n",
      "Validating:  32%|███▏      | 12/38 [00:09<00:32,  1.24s/it]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 776/799 [05:02<00:08,  2.56it/s, loss=0.248, v_num=_w10]\n",
      "Validating:  45%|████▍     | 17/38 [00:10<00:15,  1.37it/s]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 780/799 [05:02<00:07,  2.58it/s, loss=0.248, v_num=_w10]\n",
      "Epoch 6:  98%|█████████▊| 784/799 [05:04<00:05,  2.58it/s, loss=0.248, v_num=_w10]\n",
      "Validating:  66%|██████▌   | 25/38 [00:12<00:05,  2.34it/s]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 788/799 [05:04<00:04,  2.59it/s, loss=0.248, v_num=_w10]\n",
      "Epoch 6:  99%|█████████▉| 792/799 [05:05<00:02,  2.60it/s, loss=0.248, v_num=_w10]\n",
      "Epoch 6: 100%|█████████▉| 796/799 [05:06<00:01,  2.60it/s, loss=0.248, v_num=_w10]\n",
      "Validating:  97%|█████████▋| 37/38 [00:13<00:00,  4.58it/s]\u001b[A\n",
      "Epoch 00006: avg_val_loss  was not in top 1\n",
      "Epoch 6: 100%|██████████| 799/799 [05:07<00:00,  2.60it/s, loss=0.248, v_num=_w10]\n",
      "Epoch 7:  95%|█████████▌| 761/799 [04:42<00:14,  2.70it/s, loss=0.279, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 764/799 [04:47<00:13,  2.66it/s, loss=0.279, v_num=_w10]\n",
      "Validating:  11%|█         | 4/38 [00:04<01:55,  3.40s/it]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 768/799 [04:47<00:11,  2.67it/s, loss=0.279, v_num=_w10]\n",
      "Validating:  21%|██        | 8/38 [00:05<00:51,  1.70s/it]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 772/799 [04:49<00:10,  2.67it/s, loss=0.279, v_num=_w10]\n",
      "Validating:  32%|███▏      | 12/38 [00:07<00:28,  1.11s/it]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 776/799 [04:50<00:08,  2.67it/s, loss=0.279, v_num=_w10]\n",
      "Validating:  45%|████▍     | 17/38 [00:08<00:15,  1.39it/s]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 780/799 [04:50<00:07,  2.68it/s, loss=0.279, v_num=_w10]\n",
      "Epoch 7:  98%|█████████▊| 784/799 [04:52<00:05,  2.68it/s, loss=0.279, v_num=_w10]\n",
      "Validating:  63%|██████▎   | 24/38 [00:10<00:05,  2.37it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▊| 788/799 [04:53<00:04,  2.69it/s, loss=0.279, v_num=_w10]\n",
      "Validating:  76%|███████▋  | 29/38 [00:11<00:02,  3.26it/s]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 792/799 [04:53<00:02,  2.70it/s, loss=0.279, v_num=_w10]\n",
      "Epoch 7: 100%|█████████▉| 796/799 [04:54<00:01,  2.70it/s, loss=0.279, v_num=_w10]\n",
      "Validating:  97%|█████████▋| 37/38 [00:12<00:00,  3.76it/s]\u001b[A\n",
      "Epoch 00007: avg_val_loss  was not in top 1\n",
      "Epoch 7: 100%|██████████| 799/799 [04:56<00:00,  2.70it/s, loss=0.279, v_num=_w10]\n",
      "Epoch 8:  95%|█████████▌| 761/799 [04:42<00:14,  2.70it/s, loss=0.278, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 764/799 [04:45<00:13,  2.67it/s, loss=0.278, v_num=_w10]\n",
      "Validating:  11%|█         | 4/38 [00:04<01:34,  2.77s/it]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 768/799 [04:46<00:11,  2.68it/s, loss=0.278, v_num=_w10]\n",
      "Epoch 8:  97%|█████████▋| 772/799 [04:48<00:10,  2.67it/s, loss=0.278, v_num=_w10]\n",
      "Epoch 8:  97%|█████████▋| 776/799 [04:51<00:08,  2.66it/s, loss=0.278, v_num=_w10]\n",
      "Validating:  42%|████▏     | 16/38 [00:09<00:22,  1.01s/it]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 780/799 [04:51<00:07,  2.67it/s, loss=0.278, v_num=_w10]\n",
      "Validating:  53%|█████▎    | 20/38 [00:10<00:12,  1.44it/s]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 784/799 [04:53<00:05,  2.68it/s, loss=0.278, v_num=_w10]\n",
      "Validating:  66%|██████▌   | 25/38 [00:11<00:05,  2.56it/s]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 788/799 [04:53<00:04,  2.69it/s, loss=0.278, v_num=_w10]\n",
      "Epoch 8:  99%|█████████▉| 792/799 [04:53<00:02,  2.70it/s, loss=0.278, v_num=_w10]\n",
      "Epoch 8: 100%|█████████▉| 796/799 [04:54<00:01,  2.70it/s, loss=0.278, v_num=_w10]\n",
      "Validating:  97%|█████████▋| 37/38 [00:12<00:00,  5.07it/s]\u001b[A\n",
      "Epoch 00008: avg_val_loss  was not in top 1\n",
      "Epoch 8: 100%|██████████| 799/799 [04:55<00:00,  2.70it/s, loss=0.278, v_num=_w10]\n",
      "Epoch 9:  95%|█████████▌| 761/799 [04:40<00:14,  2.71it/s, loss=0.230, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 9:  96%|█████████▌| 764/799 [04:45<00:13,  2.68it/s, loss=0.230, v_num=_w10]\n",
      "Validating:  11%|█         | 4/38 [00:04<01:37,  2.87s/it]\u001b[A\n",
      "Validating:  16%|█▌        | 6/38 [00:04<01:05,  2.06s/it]\u001b[A\n",
      "Epoch 9:  96%|█████████▌| 768/799 [04:46<00:11,  2.68it/s, loss=0.230, v_num=_w10]\n",
      "Epoch 9:  97%|█████████▋| 772/799 [04:47<00:10,  2.69it/s, loss=0.230, v_num=_w10]\n",
      "Epoch 9:  97%|█████████▋| 776/799 [04:50<00:08,  2.67it/s, loss=0.230, v_num=_w10]\n",
      "Validating:  42%|████▏     | 16/38 [00:09<00:19,  1.14it/s]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 780/799 [04:51<00:07,  2.68it/s, loss=0.230, v_num=_w10]\n",
      "Epoch 9:  98%|█████████▊| 784/799 [04:52<00:05,  2.68it/s, loss=0.230, v_num=_w10]\n",
      "Validating:  63%|██████▎   | 24/38 [00:11<00:06,  2.22it/s]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 788/799 [04:52<00:04,  2.69it/s, loss=0.230, v_num=_w10]\n",
      "Epoch 9:  99%|█████████▉| 792/799 [04:53<00:02,  2.70it/s, loss=0.230, v_num=_w10]\n",
      "Validating:  84%|████████▍ | 32/38 [00:12<00:01,  4.26it/s]\u001b[A\n",
      "Epoch 9: 100%|█████████▉| 796/799 [04:53<00:01,  2.71it/s, loss=0.230, v_num=_w10]\n",
      "Validating:  95%|█████████▍| 36/38 [00:13<00:00,  4.60it/s]\u001b[A\n",
      "Epoch 00009: avg_val_loss  was not in top 1\n",
      "Epoch 9: 100%|██████████| 799/799 [04:55<00:00,  2.71it/s, loss=0.230, v_num=_w10]\n",
      "Epoch 10:  95%|█████████▌| 761/799 [04:35<00:13,  2.76it/s, loss=0.202, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 10:  96%|█████████▌| 764/799 [04:39<00:12,  2.73it/s, loss=0.202, v_num=_w10]\n",
      "Validating:  11%|█         | 4/38 [00:04<01:39,  2.93s/it]\u001b[A\n",
      "Validating:  16%|█▌        | 6/38 [00:04<01:08,  2.14s/it]\u001b[A\n",
      "Epoch 10:  96%|█████████▌| 768/799 [04:40<00:11,  2.74it/s, loss=0.202, v_num=_w10]\n",
      "Epoch 10:  97%|█████████▋| 772/799 [04:42<00:09,  2.73it/s, loss=0.202, v_num=_w10]\n",
      "Validating:  32%|███▏      | 12/38 [00:08<00:29,  1.15s/it]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 776/799 [04:44<00:08,  2.73it/s, loss=0.202, v_num=_w10]\n",
      "Epoch 10:  98%|█████████▊| 780/799 [04:44<00:06,  2.74it/s, loss=0.202, v_num=_w10]\n",
      "Validating:  53%|█████▎    | 20/38 [00:10<00:11,  1.58it/s]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 784/799 [04:46<00:05,  2.74it/s, loss=0.202, v_num=_w10]\n",
      "Epoch 10:  99%|█████████▊| 788/799 [04:46<00:04,  2.75it/s, loss=0.202, v_num=_w10]\n",
      "Epoch 10:  99%|█████████▉| 792/799 [04:46<00:02,  2.76it/s, loss=0.202, v_num=_w10]\n",
      "Validating:  84%|████████▍ | 32/38 [00:11<00:01,  4.47it/s]\u001b[A\n",
      "Epoch 10: 100%|█████████▉| 796/799 [04:48<00:01,  2.76it/s, loss=0.202, v_num=_w10]\n",
      "Validating:  97%|█████████▋| 37/38 [00:13<00:00,  3.73it/s]\u001b[A\n",
      "Epoch 00010: avg_val_loss  was not in top 1\n",
      "Epoch 10: 100%|██████████| 799/799 [04:49<00:00,  2.76it/s, loss=0.202, v_num=_w10]\n",
      "Epoch 11:  95%|█████████▌| 761/799 [04:35<00:13,  2.76it/s, loss=0.198, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 11:  96%|█████████▌| 764/799 [04:41<00:12,  2.72it/s, loss=0.198, v_num=_w10]\n",
      "Validating:  11%|█         | 4/38 [00:05<02:03,  3.64s/it]\u001b[A\n",
      "Epoch 11:  96%|█████████▌| 768/799 [04:41<00:11,  2.73it/s, loss=0.198, v_num=_w10]\n",
      "Validating:  21%|██        | 8/38 [00:05<00:54,  1.81s/it]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 772/799 [04:43<00:09,  2.73it/s, loss=0.198, v_num=_w10]\n",
      "Validating:  32%|███▏      | 12/38 [00:08<00:31,  1.23s/it]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 776/799 [04:44<00:08,  2.73it/s, loss=0.198, v_num=_w10]\n",
      "Epoch 11:  98%|█████████▊| 780/799 [04:44<00:06,  2.74it/s, loss=0.198, v_num=_w10]\n",
      "Validating:  53%|█████▎    | 20/38 [00:10<00:11,  1.51it/s]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 784/799 [04:46<00:05,  2.74it/s, loss=0.198, v_num=_w10]\n",
      "Epoch 11:  99%|█████████▊| 788/799 [04:47<00:04,  2.74it/s, loss=0.198, v_num=_w10]\n",
      "Validating:  76%|███████▋  | 29/38 [00:11<00:03,  2.85it/s]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 792/799 [04:47<00:02,  2.76it/s, loss=0.198, v_num=_w10]\n",
      "Epoch 11: 100%|█████████▉| 796/799 [04:48<00:01,  2.76it/s, loss=0.198, v_num=_w10]\n",
      "Validating:  97%|█████████▋| 37/38 [00:12<00:00,  3.57it/s]\u001b[A\n",
      "Epoch 00011: avg_val_loss  was not in top 1\n",
      "Epoch 11: 100%|██████████| 799/799 [04:49<00:00,  2.76it/s, loss=0.198, v_num=_w10]\n",
      "Epoch 12:  95%|█████████▌| 761/799 [04:39<00:13,  2.72it/s, loss=0.192, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 12:  96%|█████████▌| 764/799 [04:44<00:13,  2.69it/s, loss=0.192, v_num=_w10]\n",
      "Validating:  11%|█         | 4/38 [00:04<01:56,  3.41s/it]\u001b[A\n",
      "Epoch 12:  96%|█████████▌| 768/799 [04:44<00:11,  2.70it/s, loss=0.192, v_num=_w10]\n",
      "Validating:  21%|██        | 8/38 [00:05<00:51,  1.71s/it]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 772/799 [04:46<00:10,  2.69it/s, loss=0.192, v_num=_w10]\n",
      "Validating:  32%|███▏      | 12/38 [00:07<00:29,  1.14s/it]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 776/799 [04:47<00:08,  2.70it/s, loss=0.192, v_num=_w10]\n",
      "Validating:  42%|████▏     | 16/38 [00:08<00:15,  1.43it/s]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 780/799 [04:48<00:07,  2.71it/s, loss=0.192, v_num=_w10]\n",
      "Epoch 12:  98%|█████████▊| 784/799 [04:49<00:05,  2.71it/s, loss=0.192, v_num=_w10]\n",
      "Epoch 12:  99%|█████████▊| 788/799 [04:50<00:04,  2.71it/s, loss=0.192, v_num=_w10]\n",
      "Validating:  76%|███████▋  | 29/38 [00:11<00:03,  2.84it/s]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 792/799 [04:50<00:02,  2.72it/s, loss=0.192, v_num=_w10]\n",
      "Epoch 12: 100%|█████████▉| 796/799 [04:52<00:01,  2.72it/s, loss=0.192, v_num=_w10]\n",
      "Validating:  97%|█████████▋| 37/38 [00:13<00:00,  3.61it/s]\u001b[A\n",
      "Epoch 00012: avg_val_loss  was not in top 1\n",
      "Epoch 12: 100%|██████████| 799/799 [04:53<00:00,  2.72it/s, loss=0.192, v_num=_w10]\n",
      "Epoch 13:  95%|█████████▌| 761/799 [04:37<00:13,  2.74it/s, loss=0.158, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 13:  96%|█████████▌| 764/799 [04:42<00:12,  2.70it/s, loss=0.158, v_num=_w10]\n",
      "Validating:  11%|█         | 4/38 [00:05<01:57,  3.47s/it]\u001b[A\n",
      "Epoch 13:  96%|█████████▌| 768/799 [04:43<00:11,  2.71it/s, loss=0.158, v_num=_w10]\n",
      "Validating:  21%|██        | 8/38 [00:05<00:51,  1.73s/it]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 772/799 [04:45<00:09,  2.71it/s, loss=0.158, v_num=_w10]\n",
      "Validating:  32%|███▏      | 12/38 [00:08<00:32,  1.24s/it]\u001b[A\n",
      "Epoch 13:  97%|█████████▋| 776/799 [04:46<00:08,  2.71it/s, loss=0.158, v_num=_w10]\n",
      "Validating:  42%|████▏     | 16/38 [00:08<00:14,  1.54it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 780/799 [04:46<00:06,  2.72it/s, loss=0.158, v_num=_w10]\n",
      "Validating:  53%|█████▎    | 20/38 [00:10<00:09,  2.00it/s]\u001b[A\n",
      "Epoch 13:  98%|█████████▊| 784/799 [04:48<00:05,  2.72it/s, loss=0.158, v_num=_w10]\n",
      "Epoch 13:  99%|█████████▊| 788/799 [04:49<00:04,  2.73it/s, loss=0.158, v_num=_w10]\n",
      "Validating:  76%|███████▋  | 29/38 [00:11<00:02,  3.74it/s]\u001b[A\n",
      "Epoch 13:  99%|█████████▉| 792/799 [04:49<00:02,  2.74it/s, loss=0.158, v_num=_w10]\n",
      "Epoch 13: 100%|█████████▉| 796/799 [04:50<00:01,  2.74it/s, loss=0.158, v_num=_w10]\n",
      "Validating:  97%|█████████▋| 37/38 [00:13<00:00,  3.94it/s]\u001b[A\n",
      "Epoch 00013: avg_val_loss  was not in top 1\n",
      "Epoch 13: 100%|██████████| 799/799 [04:51<00:00,  2.74it/s, loss=0.158, v_num=_w10]\n",
      "Epoch 14:  95%|█████████▌| 761/799 [04:37<00:13,  2.74it/s, loss=0.162, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 14:  96%|█████████▌| 764/799 [04:41<00:12,  2.72it/s, loss=0.162, v_num=_w10]\n",
      "Validating:  11%|█         | 4/38 [00:04<01:30,  2.67s/it]\u001b[A\n",
      "Epoch 14:  96%|█████████▌| 768/799 [04:42<00:11,  2.72it/s, loss=0.162, v_num=_w10]\n",
      "Epoch 14:  97%|█████████▋| 772/799 [04:43<00:09,  2.72it/s, loss=0.162, v_num=_w10]\n",
      "Validating:  32%|███▏      | 12/38 [00:09<00:35,  1.36s/it]\u001b[A\n",
      "Epoch 14:  97%|█████████▋| 776/799 [04:46<00:08,  2.71it/s, loss=0.162, v_num=_w10]\n",
      "Validating:  45%|████▍     | 17/38 [00:09<00:14,  1.44it/s]\u001b[A\n",
      "Epoch 14:  98%|█████████▊| 780/799 [04:46<00:06,  2.72it/s, loss=0.162, v_num=_w10]\n",
      "Epoch 14:  98%|█████████▊| 784/799 [04:48<00:05,  2.72it/s, loss=0.162, v_num=_w10]\n",
      "Epoch 14:  99%|█████████▊| 788/799 [04:48<00:04,  2.73it/s, loss=0.162, v_num=_w10]\n",
      "Epoch 14:  99%|█████████▉| 792/799 [04:48<00:02,  2.74it/s, loss=0.162, v_num=_w10]\n",
      "Validating:  84%|████████▍ | 32/38 [00:11<00:01,  4.45it/s]\u001b[A\n",
      "Epoch 14: 100%|█████████▉| 796/799 [04:50<00:01,  2.74it/s, loss=0.162, v_num=_w10]\n",
      "Validating:  97%|█████████▋| 37/38 [00:13<00:00,  3.82it/s]\u001b[A\n",
      "Epoch 00014: avg_val_loss  was not in top 1\n",
      "Epoch 14: 100%|██████████| 799/799 [04:51<00:00,  2.74it/s, loss=0.162, v_num=_w10]\n",
      "Epoch 15:  95%|█████████▌| 761/799 [04:52<00:14,  2.60it/s, loss=0.149, v_num=_w10]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   3%|▎         | 1/38 [00:04<02:30,  4.06s/it]\u001b[A\n",
      "Epoch 15:  96%|█████████▌| 764/799 [04:56<00:13,  2.58it/s, loss=0.149, v_num=_w10]\n",
      "Validating:  11%|█         | 4/38 [00:04<01:09,  2.05s/it]\u001b[A\n",
      "Epoch 15:  96%|█████████▌| 768/799 [04:57<00:12,  2.58it/s, loss=0.149, v_num=_w10]\n",
      "Validating:  24%|██▎       | 9/38 [00:06<00:35,  1.24s/it]\u001b[A\n",
      "Epoch 15:  97%|█████████▋| 772/799 [04:58<00:10,  2.58it/s, loss=0.149, v_num=_w10]\n",
      "Validating:  32%|███▏      | 12/38 [00:09<00:40,  1.54s/it]\u001b[A\n",
      "Epoch 15:  97%|█████████▋| 776/799 [05:02<00:08,  2.57it/s, loss=0.149, v_num=_w10]\n",
      "Validating:  45%|████▍     | 17/38 [00:10<00:16,  1.27it/s]\u001b[A\n",
      "Epoch 15:  98%|█████████▊| 780/799 [05:02<00:07,  2.58it/s, loss=0.149, v_num=_w10]\n",
      "Epoch 15:  98%|█████████▊| 784/799 [05:03<00:05,  2.58it/s, loss=0.149, v_num=_w10]\n",
      "Validating:  63%|██████▎   | 24/38 [00:11<00:05,  2.35it/s]\u001b[A\n",
      "Epoch 15:  99%|█████████▊| 788/799 [05:03<00:04,  2.59it/s, loss=0.149, v_num=_w10]\n",
      "Epoch 15:  99%|█████████▉| 792/799 [05:04<00:02,  2.60it/s, loss=0.149, v_num=_w10]\n",
      "Validating:  84%|████████▍ | 32/38 [00:12<00:01,  4.35it/s]\u001b[A\n",
      "Epoch 15: 100%|█████████▉| 796/799 [05:05<00:01,  2.61it/s, loss=0.149, v_num=_w10]\n",
      "Validating:  95%|█████████▍| 36/38 [00:13<00:00,  4.69it/s]\u001b[A\n",
      "Epoch 00015: avg_val_loss  was not in top 1\n",
      "Epoch 15: 100%|██████████| 799/799 [05:06<00:00,  2.61it/s, loss=0.149, v_num=_w10]\n",
      "                                                           \u001b[ASaving latest checkpoint..\n",
      "Epoch 15: 100%|██████████| 799/799 [05:06<00:00,  2.61it/s, loss=0.149, v_num=_w10]\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action              \t|  Mean duration (s)\t|  Total time (s) \n",
      "-----------------------------------------------------------------\n",
      "on_validation_epoch_start\t|  1.5144e-05     \t|  0.00025745     \n",
      "on_validation_epoch_end\t|  1.5144e-05     \t|  0.00025744     \n",
      "on_train_start      \t|  0.00073387     \t|  0.00073387     \n",
      "on_epoch_start      \t|  0.0012511      \t|  0.020017       \n",
      "on_train_epoch_start\t|  1.0466e-05     \t|  0.00016745     \n",
      "get_train_batch     \t|  0.0051327      \t|  62.578         \n",
      "on_batch_start      \t|  1.8399e-05     \t|  0.22403        \n",
      "on_train_batch_start\t|  1.0016e-05     \t|  0.12195        \n",
      "model_forward       \t|  0.034305       \t|  417.7          \n",
      "model_backward      \t|  0.03749        \t|  456.48         \n",
      "on_after_backward   \t|  4.403e-06      \t|  0.05361        \n",
      "optimizer_step      \t|  0.13927        \t|  1695.8         \n",
      "on_batch_end        \t|  2.1939e-05     \t|  0.26713        \n",
      "on_train_batch_end  \t|  0.0021897      \t|  26.662         \n",
      "on_epoch_end        \t|  1.1857e-05     \t|  0.00018971     \n",
      "on_train_epoch_end  \t|  1.1347e-05     \t|  0.00018156     \n",
      "on_train_end        \t|  0.00074237     \t|  0.00074237     \n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "trainer.fit(lightning_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metrics(conf=config, metric='accuracy', scale='linear', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing:  97%|█████████▋| 37/38 [00:13<00:00,  4.85it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_accuracy': tensor(0.9367, device='cuda:0'),\n",
      " 'avg_test_loss': tensor(0.3952, device='cuda:0'),\n",
      " 'loss': tensor(0.3952, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 38/38 [00:13<00:00,  2.85it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'avg_test_loss': 0.3952120840549469,\n",
       "  'avg_test_accuracy': 0.9366883039474487,\n",
       "  'loss': 0.3952120840549469}]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "trainer.test(\n",
    "    model=lightning_model,\n",
    "    ckpt_path=lightning_model.fm.model_checkpoint(\"last\").as_posix()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}