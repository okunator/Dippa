{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leos/.local/lib/python3.6/site-packages/pandas/compat/_optional.py:106: UserWarning: Pandas requires version '1.2.1' or newer of 'bottleneck' (version '1.2.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "from pathlib import Path\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.logging import TestTubeLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from omegaconf import OmegaConf \n",
    "from src.conf.conf_schema import Schema\n",
    "from src.conf.config import CONFIG\n",
    "from src.dl.lightning_model import SegModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a pytorch model\n",
    "\n",
    "- Any model should work if it's wrapped to lightning SegModel wrapper. e.g. smp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnext50_32x4d\", \n",
    "    classes=2\n",
    ")\n",
    "\n",
    "# model = smp.FPN(\n",
    "#     encoder_name=\"resnext50_32x4d\", \n",
    "#     classes=2, \n",
    "#     decoder_merge_policy='cat'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.merge(Schema, CONFIG)\n",
    "lightning_model = SegModel.from_conf(model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up lightning trainers and loggers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leos/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning:\n",
      "\n",
      "Checkpoint directory /home/local/leos/Dippa_test/result/Unet/version_test_pannuke_ddd exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "tt_logger = TestTubeLogger(\n",
    "    save_dir=config.experiment_args.experiment_root_dir,\n",
    "    name=config.experiment_args.model_name,\n",
    "    version=config.experiment_args.experiment_version\n",
    ")\n",
    "\n",
    "checkpoint_dir = (\n",
    "    Path(tt_logger.save_dir)\n",
    "    / tt_logger.experiment.name\n",
    "    / f\"version_{tt_logger.experiment.version}\"\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath = str(checkpoint_dir),\n",
    "    save_top_k = 1,\n",
    "    save_last = True,\n",
    "    verbose = True, \n",
    "    monitor = 'avg_val_loss',\n",
    "    mode = 'min',\n",
    "    prefix = ''\n",
    ")\n",
    "\n",
    "if config.training_args.resume_training:   \n",
    "    last_checkpoint_path = lightning_model.fm.model_checkpoint(\"last\")\n",
    "    trainer = Trainer(\n",
    "        default_root_dir=config.experiment_args.experiment_root_dir,\n",
    "        max_epochs=config.training_args.num_epochs, \n",
    "        gpus=config.training_args.num_gpus,  \n",
    "        logger=tt_logger,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        resume_from_checkpoint=str(last_checkpoint_path),\n",
    "        profiler=True,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    trainer = Trainer(\n",
    "        default_root_dir=config.experiment_args.experiment_root_dir,\n",
    "        max_epochs=config.training_args.num_epochs, \n",
    "        gpus=config.training_args.num_gpus,  \n",
    "        logger=tt_logger,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        profiler=True,\n",
    "    )\n",
    "    \n",
    "\n",
    "# find the batch size automatically\n",
    "# new_batch_size = trainer.scale_batch_size(lightning_model)\n",
    "\n",
    "# Override old batch size\n",
    "# lightning_model.batch_size = new_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = (\n",
    "    Path(tt_logger.save_dir)\n",
    "    / tt_logger.experiment.name\n",
    "    / f\"version_{tt_logger.experiment.version}\"\n",
    "    / \"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 19547), started 0:06:09 ago. (Use '!kill 19547' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7ad9f1776608696d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7ad9f1776608696d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | Unet             | 31 M  \n",
      "1 | CE    | CrossEntropyLoss | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc7c70af54c4260b044880ca69d1013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(lightning_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(conf=config, metric='accuracy', scale='linear', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(\n",
    "    model=lightning_model,\n",
    "    ckpt_path = lightning_model.fm.model_checkpoint(\"best\").as_posix()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
