{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/local/leos/Dippa/DippaEnv/lib/python3.6/site-packages/torchvision/extension.py:11: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.BufferedReader name='/home/local/leos/Dippa/DippaEnv/lib/python3.6/site-packages/torchvision/_C.so'>\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint #GpuUsageLogger\n",
    "from src.settings import RESULT_DIR\n",
    "from src.config import CONFIG\n",
    "from src.dl.lightning_model import SegModel\n",
    "from src.dl.models.model_builder import ModelBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a pytorch model\n",
    "\n",
    "- Any model should work if it's wrapped to lightning SegModel wrapper. e.g. smp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the config file\n",
    "config = CONFIG\n",
    "\n",
    "# Set the model to do instance or panoptic segmentation (depends what's in the config.py file)\n",
    "base_model = ModelBuilder.set_model(config, relu_to_mish=False, merge_policy=\"cat\")\n",
    "\n",
    "# Insert the model to pytorch lightning framework. (Simplifies the training and other stuff)\n",
    "lightning_model = SegModel.from_conf(base_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/local/leos/Dippa/DippaEnv/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning:\n",
      "\n",
      "Checkpoint directory /home/local/leos/Dippa/results/tests/unet/version_attention-unet-hover exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "tt_logger = pl_loggers.TestTubeLogger(\n",
    "    save_dir=RESULT_DIR,\n",
    "    name=config.experiment_args.model_name,\n",
    "    version=config.experiment_args.experiment_version\n",
    ")\n",
    "\n",
    "checkpoint_dir = (\n",
    "    Path(tt_logger.save_dir)\n",
    "    / tt_logger.experiment.name\n",
    "    / f\"version_{tt_logger.experiment.version}\"\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath = str(checkpoint_dir),\n",
    "    save_top_k = 1,\n",
    "    save_last = True,\n",
    "    verbose = True, \n",
    "    monitor = 'avg_val_loss',\n",
    "    mode = 'min',\n",
    "    prefix = ''\n",
    ")\n",
    "\n",
    "if config.training_args.resume_training:   \n",
    "    last_checkpoint_path = lightning_model.fm.model_checkpoint(\"last\")\n",
    "    trainer = Trainer(\n",
    "        default_root_dir=config.experiment_args.experiment_root_dir,\n",
    "        max_epochs=config.training_args.num_epochs, \n",
    "        gpus=config.training_args.num_gpus,  \n",
    "        logger=tt_logger,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        #callbacks=[GPUStatsMonitor()],\n",
    "        resume_from_checkpoint=str(last_checkpoint_path),\n",
    "        profiler=True,\n",
    "        # gradient_clip_val=0.5\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    trainer = Trainer(\n",
    "        default_root_dir=config.experiment_args.experiment_root_dir,\n",
    "        max_epochs=config.training_args.num_epochs, \n",
    "        gpus=config.training_args.num_gpus,  \n",
    "        logger=tt_logger,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        # callbacks=[GpuUsageLogger()],\n",
    "        profiler=True,\n",
    "        # gradient_clip_val=0.5\n",
    "    )\n",
    "    \n",
    "\n",
    "# find the batch size automatically\n",
    "# new_batch_size = trainer.scale_batch_size(lightning_model)\n",
    "\n",
    "# Override old batch size\n",
    "# lightning_model.batch_size = new_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = (\n",
    "    Path(tt_logger.save_dir)\n",
    "    / tt_logger.experiment.name\n",
    "    / f\"version_{tt_logger.experiment.version}\"\n",
    "    / \"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Reusing TensorBoard on port 6006 (pid 26031), started 0:00:45 ago. (Use '!kill 26031' to kill it.)"
     },
     "metadata": {}
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "  | Name      | Type                 | Params\n",
      "---------------------------------------------------\n",
      "0 | model     | UnetSmpWithClsBranch | 50 M  \n",
      "1 | criterion | JointPanopticLoss    | 0     \n",
      "Epoch 1:   2%|‚ñè         | 53/2394 [00:13<09:48,  3.98it/s, loss=2.774, v_num=attention-unet-hover]"
     ]
    }
   ],
   "source": [
    "trainer.fit(lightning_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/local/leos/Dippa/DippaEnv/lib/python3.6/site-packages/catalyst/contrib/tools/tensorboard.py:43: DeprecationWarning:\n\ncrc32c.crc32 will be eventually removed, use crc32c.crc32c instead\n\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b4b91e7d3238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlightning_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mean_iou\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/local/leos/Dippa/src/dl/lightning_model.py\u001b[0m in \u001b[0;36mplot_metrics\u001b[0;34m(self, scale, metric, save)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0;34m\"training iou\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp_train_iou\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;34m\"validation iou\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp_valid_iou\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp_epochs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_train_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         }\n\u001b[1;32m    453\u001b[0m         )\n",
      "\u001b[0;32m/home/local/leos/Dippa/DippaEnv/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/local/leos/Dippa/DippaEnv/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/local/leos/Dippa/DippaEnv/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/local/leos/Dippa/DippaEnv/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "lightning_model.plot_metrics(metric=\"mean_iou\", scale='linear', save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:14<00:00,  4.47it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_accuracy': tensor(0.9348, device='cuda:0'),\n",
      " 'avg_test_iou': tensor(0.6201, device='cuda:0'),\n",
      " 'avg_test_loss': tensor(0.1692, device='cuda:0'),\n",
      " 'loss': tensor(0.1692, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:14<00:00,  1.95it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'avg_test_loss': 0.16919450461864471,\n",
       "  'avg_test_accuracy': 0.9347854852676392,\n",
       "  'avg_test_iou': 0.6200965046882629,\n",
       "  'loss': 0.16919450461864471}]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "trainer.test(\n",
    "    model=lightning_model,\n",
    "    ckpt_path=lightning_model.fm.model_checkpoint(\"last\").as_posix()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([512])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([1024])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([2048])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<ctypes.LibraryLoader object at 0x7f7e4d54d9b0>\n",
      "<ctypes.LibraryLoader object at 0x7f7e4d54d9e8>\n",
      "<torch.jit.annotations.Module object at 0x7f7dc0a5ac50>\n",
      "<torch.jit.annotations.Module object at 0x7f7dc0a5ac88>\n",
      "/home/leos/.local/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning:\n",
      "\n",
      "torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "\n",
      "/usr/lib/python3.6/importlib/__init__.py:126: H5pyDeprecationWarning:\n",
      "\n",
      "The h5py.highlevel module is deprecated, code should import directly from h5py, e.g. 'from h5py import File'.\n",
      "\n",
      "\n",
      "absl.app:\n",
      "  --[no]only_check_args: Set to true to validate args and exit.\n",
      "    (default: 'false')\n",
      "  --[no]pdb_post_mortem: Set to true to handle uncaught exceptions with PDB post\n",
      "    mortem.\n",
      "    (default: 'false')\n",
      "  --profile_file: Dump profile information to a file (for python -m pstats).\n",
      "    Implies --run_with_profiling.\n",
      "  --[no]run_with_pdb: Set to true for PDB debug mode\n",
      "    (default: 'false')\n",
      "  --[no]run_with_profiling: Set to true for profiling the script. Execution will\n",
      "    be slower, and the output format might change over time.\n",
      "    (default: 'false')\n",
      "  --[no]use_cprofile_for_profiling: Use cProfile instead of the profile module\n",
      "    for profiling. This has no effect unless --run_with_profiling is set.\n",
      "    (default: 'true')\n",
      "\n",
      "absl.logging:\n",
      "  --[no]alsologtostderr: also log to stderr?\n",
      "    (default: 'false')\n",
      "  --log_dir: directory to write logfiles into\n",
      "    (default: '')\n",
      "  --[no]logtostderr: Should only log to stderr?\n",
      "    (default: 'false')\n",
      "  --[no]showprefixforinfo: If False, do not prepend prefix to info messages when\n",
      "    it's logged to stderr, --verbosity is set to INFO level, and python logging\n",
      "    is used.\n",
      "    (default: 'true')\n",
      "  --stderrthreshold: log messages at this level, or more severe, to stderr in\n",
      "    addition to the logfile.  Possible values are 'debug', 'info', 'warning',\n",
      "    'error', and 'fatal'.  Obsoletes --alsologtostderr. Using --alsologtostderr\n",
      "    cancels the effect of this flag. Please also note that this flag is subject\n",
      "    to --verbosity and requires logfile not be stderr.\n",
      "    (default: 'fatal')\n",
      "  -v,--verbosity: Logging verbosity level. Messages logged at this level or\n",
      "    lower will be included. Set to 1 for debug logging. If the flag was not set\n",
      "    or supplied, the value will be changed from the default of -1 (warning) to 0\n",
      "    (info) after flags are parsed.\n",
      "    (default: '-1')\n",
      "    (an integer)\n",
      "\n",
      "absl.testing.absltest:\n",
      "  --test_random_seed: Random seed for testing. Some test frameworks may change\n",
      "    the default value of this flag between runs, so it is not appropriate for\n",
      "    seeding probabilistic tests.\n",
      "    (default: '301')\n",
      "    (an integer)\n",
      "  --test_randomize_ordering_seed: If positive, use this as a seed to randomize\n",
      "    the execution order for test cases. If \"random\", pick a random seed to use.\n",
      "    If 0 or not set, do not randomize test case execution order. This flag also\n",
      "    overrides the TEST_RANDOMIZE_ORDERING_SEED environment variable.\n",
      "    (default: '')\n",
      "  --test_srcdir: Root of directory tree where source files live\n",
      "    (default: '')\n",
      "  --test_tmpdir: Directory for temporary testing files\n",
      "    (default: '/tmp/absl_testing')\n",
      "  --xml_output_file: File to store XML test results\n",
      "    (default: '')\n",
      "\n",
      "tensorflow.python.ops.parallel_for.pfor:\n",
      "  --[no]op_conversion_fallback_to_while_loop: If true, falls back to using a\n",
      "    while loop for ops for which a converter is not defined.\n",
      "    (default: 'false')\n",
      "\n",
      "absl.flags:\n",
      "  --flagfile: Insert flag definitions from the given file into the command line.\n",
      "    (default: '')\n",
      "  --undefok: comma-separated list of flag names that it is okay to specify on\n",
      "    the command line even if the program does not define a flag with that name.\n",
      "    IMPORTANT: flags in this list that have arguments MUST use the --flag=value\n",
      "    format.\n",
      "    (default: '')\n",
      "/home/leos/.local/lib/python3.6/site-packages/pandas/util/__init__.py:23: FutureWarning:\n",
      "\n",
      "pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning:\n",
      "\n",
      "The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning:\n",
      "\n",
      "The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/scipy/_lib/_util.py:169: DeprecationWarning:\n",
      "\n",
      "Module scipy.linalg.blas.clapack is deprecated, use scipy.linalg.lapack instead\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/scipy/_lib/_util.py:169: DeprecationWarning:\n",
      "\n",
      "Module scipy.linalg.blas.flapack is deprecated, use scipy.linalg.lapack instead\n",
      "\n",
      "\n",
      "absl.app:\n",
      "  --[no]only_check_args: Set to true to validate args and exit.\n",
      "    (default: 'false')\n",
      "  --[no]pdb_post_mortem: Set to true to handle uncaught exceptions with PDB post\n",
      "    mortem.\n",
      "    (default: 'false')\n",
      "  --profile_file: Dump profile information to a file (for python -m pstats).\n",
      "    Implies --run_with_profiling.\n",
      "  --[no]run_with_pdb: Set to true for PDB debug mode\n",
      "    (default: 'false')\n",
      "  --[no]run_with_profiling: Set to true for profiling the script. Execution will\n",
      "    be slower, and the output format might change over time.\n",
      "    (default: 'false')\n",
      "  --[no]use_cprofile_for_profiling: Use cProfile instead of the profile module\n",
      "    for profiling. This has no effect unless --run_with_profiling is set.\n",
      "    (default: 'true')\n",
      "\n",
      "absl.logging:\n",
      "  --[no]alsologtostderr: also log to stderr?\n",
      "    (default: 'false')\n",
      "  --log_dir: directory to write logfiles into\n",
      "    (default: '')\n",
      "  --[no]logtostderr: Should only log to stderr?\n",
      "    (default: 'false')\n",
      "  --[no]showprefixforinfo: If False, do not prepend prefix to info messages when\n",
      "    it's logged to stderr, --verbosity is set to INFO level, and python logging\n",
      "    is used.\n",
      "    (default: 'true')\n",
      "  --stderrthreshold: log messages at this level, or more severe, to stderr in\n",
      "    addition to the logfile.  Possible values are 'debug', 'info', 'warning',\n",
      "    'error', and 'fatal'.  Obsoletes --alsologtostderr. Using --alsologtostderr\n",
      "    cancels the effect of this flag. Please also note that this flag is subject\n",
      "    to --verbosity and requires logfile not be stderr.\n",
      "    (default: 'fatal')\n",
      "  -v,--verbosity: Logging verbosity level. Messages logged at this level or\n",
      "    lower will be included. Set to 1 for debug logging. If the flag was not set\n",
      "    or supplied, the value will be changed from the default of -1 (warning) to 0\n",
      "    (info) after flags are parsed.\n",
      "    (default: '-1')\n",
      "    (an integer)\n",
      "\n",
      "absl.testing.absltest:\n",
      "  --test_random_seed: Random seed for testing. Some test frameworks may change\n",
      "    the default value of this flag between runs, so it is not appropriate for\n",
      "    seeding probabilistic tests.\n",
      "    (default: '301')\n",
      "    (an integer)\n",
      "  --test_randomize_ordering_seed: If positive, use this as a seed to randomize\n",
      "    the execution order for test cases. If \"random\", pick a random seed to use.\n",
      "    If 0 or not set, do not randomize test case execution order. This flag also\n",
      "    overrides the TEST_RANDOMIZE_ORDERING_SEED environment variable.\n",
      "    (default: '')\n",
      "  --test_srcdir: Root of directory tree where source files live\n",
      "    (default: '')\n",
      "  --test_tmpdir: Directory for temporary testing files\n",
      "    (default: '/tmp/absl_testing')\n",
      "  --xml_output_file: File to store XML test results\n",
      "    (default: '')\n",
      "\n",
      "tensorflow.python.ops.parallel_for.pfor:\n",
      "  --[no]op_conversion_fallback_to_while_loop: If true, falls back to using a\n",
      "    while loop for ops for which a converter is not defined.\n",
      "    (default: 'false')\n",
      "\n",
      "absl.flags:\n",
      "  --flagfile: Insert flag definitions from the given file into the command line.\n",
      "    (default: '')\n",
      "  --undefok: comma-separated list of flag names that it is okay to specify on\n",
      "    the command line even if the program does not define a flag with that name.\n",
      "    IMPORTANT: flags in this list that have arguments MUST use the --flag=value\n",
      "    format.\n",
      "    (default: '')\n",
      "<class 'torch.Tensor'> torch.Size([])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "PyAsn1Error",
     "evalue": "Attempted \"__str__\" operation on ASN.1 schema object",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPyAsn1Error\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1253055d3325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyasn1/type/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyAsn1Error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted \"%s\" operation on ASN.1 schema object'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPyAsn1Error\u001b[0m: Attempted \"data\" operation on ASN.1 schema object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPyAsn1Error\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1253055d3325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pyasn1/type/base.py\u001b[0m in \u001b[0;36mplug\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mgetPlug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mplug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyAsn1Error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted \"%s\" operation on ASN.1 schema object'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mplug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPyAsn1Error\u001b[0m: Attempted \"__str__\" operation on ASN.1 schema object"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import gc\n",
    "# for obj in gc.get_objects():\n",
    "#     try:\n",
    "#         if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "#             print(type(obj), obj.size())\n",
    "#     except:\n",
    "#         print(obj)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('DippaEnv')",
   "metadata": {
    "interpreter": {
     "hash": "3ea01dde592f11f139bb8a18f7472b919436c8f8399691d376fd4b0010891aeb"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}