{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/home/leos/.local/lib/python3.6/site-packages/torchvision/extension.py:11: ResourceWarning:\n",
      "\n",
      "unclosed file <_io.BufferedReader name='/home/leos/.local/lib/python3.6/site-packages/torchvision/_C.so'>\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning:\n",
      "\n",
      "can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint #GpuUsageLogger\n",
    "from src.settings import RESULT_DIR\n",
    "from src.conf.config import CONFIG\n",
    "from src.dl.lightning_model import SegModel, plot_metrics\n",
    "from src.dl.model_builder import ModelBuilder\n",
    "from src.dl.loss_builder import LossBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a pytorch model\n",
    "\n",
    "- Any model should work if it's wrapped to lightning SegModel wrapper. e.g. smp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the config file\n",
    "config = CONFIG\n",
    "\n",
    "# Set the model to do instance or panoptic segmentation (depends what's in the config.py file)\n",
    "base_model = ModelBuilder.set_model(\"Unet\", config)\n",
    "\n",
    "# Insert the model to pytorch lightning framework. (Simplifies the training and other stuff)\n",
    "lightning_model = SegModel.from_conf(base_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/leos/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning:\n",
      "\n",
      "Checkpoint directory /home/local/leos/Dippa/results/tests/UNET/version_panoptic_hover_nope_test5th exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "tt_logger = pl_loggers.TestTubeLogger(\n",
    "    save_dir=RESULT_DIR,\n",
    "    name=config.experiment_args.model_name,\n",
    "    version=config.experiment_args.experiment_version\n",
    ")\n",
    "\n",
    "checkpoint_dir = (\n",
    "    Path(tt_logger.save_dir)\n",
    "    / tt_logger.experiment.name\n",
    "    / f\"version_{tt_logger.experiment.version}\"\n",
    ")\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath = str(checkpoint_dir),\n",
    "    save_top_k = 1,\n",
    "    save_last = True,\n",
    "    verbose = True, \n",
    "    monitor = 'avg_val_loss',\n",
    "    mode = 'min',\n",
    "    prefix = ''\n",
    ")\n",
    "\n",
    "if config.training_args.resume_training:   \n",
    "    last_checkpoint_path = lightning_model.fm.model_checkpoint(\"last\")\n",
    "    trainer = Trainer(\n",
    "        default_root_dir=config.experiment_args.experiment_root_dir,\n",
    "        max_epochs=config.training_args.num_epochs, \n",
    "        gpus=config.training_args.num_gpus,  \n",
    "        logger=tt_logger,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        #callbacks=[GPUStatsMonitor()],\n",
    "        resume_from_checkpoint=str(last_checkpoint_path),\n",
    "        profiler=True,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    trainer = Trainer(\n",
    "        default_root_dir=config.experiment_args.experiment_root_dir,\n",
    "        max_epochs=config.training_args.num_epochs, \n",
    "        gpus=config.training_args.num_gpus,  \n",
    "        logger=tt_logger,\n",
    "        checkpoint_callback=checkpoint_callback,\n",
    "        # callbacks=[GpuUsageLogger()],\n",
    "        profiler=True,\n",
    "    )\n",
    "    \n",
    "\n",
    "# find the batch size automatically\n",
    "# new_batch_size = trainer.scale_batch_size(lightning_model)\n",
    "\n",
    "# Override old batch size\n",
    "# lightning_model.batch_size = new_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = (\n",
    "    Path(tt_logger.save_dir)\n",
    "    / tt_logger.experiment.name\n",
    "    / f\"version_{tt_logger.experiment.version}\"\n",
    "    / \"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "ERROR: Could not find `tensorboard`. Please ensure that your PATH\ncontains an executable `tensorboard` program, or explicitly specify\nthe path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\nenvironment variable."
     },
     "metadata": {}
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/leos/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning:\n",
      "\n",
      "Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "\n",
      "\n",
      "  | Name      | Type                  | Params\n",
      "----------------------------------------------------\n",
      "0 | model     | SmpModelWithClsBranch | 41 M  \n",
      "1 | criterion | JointPanopticLoss     | 0     \n",
      "Epoch 0:  95%|█████████▌| 761/799 [04:49<00:14,  2.63it/s, loss=0.343, v_num=t5th]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  95%|█████████▌| 762/799 [04:53<00:14,  2.59it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  95%|█████████▌| 763/799 [04:54<00:13,  2.59it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  96%|█████████▌| 765/799 [04:54<00:13,  2.60it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  96%|█████████▌| 767/799 [04:54<00:12,  2.60it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  96%|█████████▌| 769/799 [04:55<00:11,  2.61it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  96%|█████████▋| 771/799 [04:56<00:10,  2.60it/s, loss=0.343, v_num=t5th]\n",
      "Validating:  29%|██▉       | 11/38 [00:06<00:18,  1.48it/s]\u001b[A\n",
      "Epoch 0:  97%|█████████▋| 773/799 [04:59<00:10,  2.58it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  97%|█████████▋| 775/799 [04:59<00:09,  2.59it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  97%|█████████▋| 777/799 [04:59<00:08,  2.60it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  97%|█████████▋| 779/799 [04:59<00:07,  2.60it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  98%|█████████▊| 781/799 [05:00<00:06,  2.60it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  98%|█████████▊| 783/799 [05:00<00:06,  2.60it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  98%|█████████▊| 785/799 [05:00<00:05,  2.61it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  98%|█████████▊| 787/799 [05:01<00:04,  2.61it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  99%|█████████▊| 789/799 [05:01<00:03,  2.62it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  99%|█████████▉| 791/799 [05:01<00:03,  2.62it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  99%|█████████▉| 793/799 [05:01<00:02,  2.63it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0:  99%|█████████▉| 795/799 [05:02<00:01,  2.63it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0: 100%|█████████▉| 797/799 [05:02<00:00,  2.63it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 0: 100%|██████████| 799/799 [05:02<00:00,  2.64it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 00000: avg_val_loss reached 0.35223 (best 0.35223), saving model to /home/local/leos/Dippa/results/tests/UNET/version_panoptic_hover_nope_test5th/epoch=0.ckpt as top 1\n",
      "Epoch 0: 100%|██████████| 799/799 [05:04<00:00,  2.62it/s, loss=0.343, v_num=t5th]\n",
      "Epoch 1:  95%|█████████▌| 761/799 [04:46<00:14,  2.66it/s, loss=0.274, v_num=t5th]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 762/799 [04:51<00:14,  2.61it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  96%|█████████▌| 764/799 [04:51<00:13,  2.62it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  96%|█████████▌| 766/799 [04:51<00:12,  2.62it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  96%|█████████▌| 768/799 [04:52<00:11,  2.63it/s, loss=0.274, v_num=t5th]\n",
      "Validating:  21%|██        | 8/38 [00:06<00:41,  1.38s/it]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 770/799 [04:53<00:11,  2.62it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  97%|█████████▋| 772/799 [04:53<00:10,  2.63it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  97%|█████████▋| 774/799 [04:55<00:09,  2.62it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  97%|█████████▋| 776/799 [04:55<00:08,  2.63it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  97%|█████████▋| 778/799 [04:55<00:07,  2.63it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  98%|█████████▊| 780/799 [04:55<00:07,  2.64it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  98%|█████████▊| 782/799 [04:56<00:06,  2.64it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  98%|█████████▊| 784/799 [04:56<00:05,  2.64it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  98%|█████████▊| 786/799 [04:57<00:04,  2.64it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  99%|█████████▊| 788/799 [04:58<00:04,  2.64it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  99%|█████████▉| 790/799 [04:58<00:03,  2.65it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  99%|█████████▉| 792/799 [04:58<00:02,  2.65it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1:  99%|█████████▉| 794/799 [04:59<00:01,  2.65it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1: 100%|█████████▉| 796/799 [04:59<00:01,  2.66it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 1: 100%|█████████▉| 798/799 [04:59<00:00,  2.66it/s, loss=0.274, v_num=t5th]\n",
      "Validating: 100%|██████████| 38/38 [00:13<00:00,  5.96it/s]\u001b[A\n",
      "Epoch 00001: avg_val_loss reached 0.31049 (best 0.31049), saving model to /home/local/leos/Dippa/results/tests/UNET/version_panoptic_hover_nope_test5th/epoch=1.ckpt as top 1\n",
      "Epoch 1: 100%|██████████| 799/799 [05:01<00:00,  2.65it/s, loss=0.274, v_num=t5th]\n",
      "Epoch 2:  95%|█████████▌| 761/799 [04:53<00:14,  2.59it/s, loss=0.220, v_num=t5th]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 762/799 [04:58<00:14,  2.55it/s, loss=0.220, v_num=t5th]\n",
      "Validating:   5%|▌         | 2/38 [00:05<02:13,  3.70s/it]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 764/799 [04:59<00:13,  2.56it/s, loss=0.220, v_num=t5th]\n",
      "Validating:  11%|█         | 4/38 [00:05<01:03,  1.87s/it]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 766/799 [04:59<00:12,  2.56it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  96%|█████████▌| 768/799 [04:59<00:12,  2.57it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  96%|█████████▋| 770/799 [05:01<00:11,  2.56it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  97%|█████████▋| 772/799 [05:01<00:10,  2.56it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  97%|█████████▋| 774/799 [05:02<00:09,  2.56it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  97%|█████████▋| 776/799 [05:03<00:08,  2.56it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  97%|█████████▋| 778/799 [05:03<00:08,  2.57it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  98%|█████████▊| 780/799 [05:03<00:07,  2.57it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  98%|█████████▊| 782/799 [05:04<00:06,  2.57it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  98%|█████████▊| 784/799 [05:04<00:05,  2.57it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  98%|█████████▊| 786/799 [05:05<00:05,  2.57it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  99%|█████████▊| 788/799 [05:05<00:04,  2.58it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  99%|█████████▉| 790/799 [05:05<00:03,  2.58it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  99%|█████████▉| 792/799 [05:06<00:02,  2.59it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2:  99%|█████████▉| 794/799 [05:07<00:01,  2.58it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2: 100%|█████████▉| 796/799 [05:07<00:01,  2.59it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 2: 100%|█████████▉| 798/799 [05:07<00:00,  2.60it/s, loss=0.220, v_num=t5th]\n",
      "Validating: 100%|██████████| 38/38 [00:13<00:00,  6.00it/s]\u001b[A\n",
      "Epoch 00002: avg_val_loss reached 0.29857 (best 0.29857), saving model to /home/local/leos/Dippa/results/tests/UNET/version_panoptic_hover_nope_test5th/epoch=2.ckpt as top 1\n",
      "Epoch 2: 100%|██████████| 799/799 [05:09<00:00,  2.58it/s, loss=0.220, v_num=t5th]\n",
      "Epoch 3:  39%|███▉      | 313/799 [02:04<03:13,  2.51it/s, loss=0.218, v_num=t5th]"
     ]
    }
   ],
   "source": [
    "trainer.fit(lightning_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metrics(conf=config, metric='accuracy', scale='linear', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/leos/.local/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:37: UserWarning:\n",
      "\n",
      "You're resuming from a checkpoint that ended mid-epoch. This can cause unreliable results if further training is done, consider using an end of epoch checkpoint. \n",
      "\n",
      "Testing:  97%|█████████▋| 37/38 [00:14<00:00,  5.94it/s]--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'avg_test_accuracy': tensor(0.9416, device='cuda:0'),\n",
      " 'avg_test_iou': tensor(0.6090, device='cuda:0'),\n",
      " 'avg_test_loss': tensor(0.4734, device='cuda:0'),\n",
      " 'loss': tensor(0.4734, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "Testing: 100%|██████████| 38/38 [00:14<00:00,  2.55it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'avg_test_loss': 0.4733676314353943,\n",
       "  'avg_test_accuracy': 0.9415586590766907,\n",
       "  'avg_test_iou': 0.6089650988578796,\n",
       "  'loss': 0.4733676314353943}]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "trainer.test(\n",
    "    model=lightning_model,\n",
    "    ckpt_path=lightning_model.fm.model_checkpoint(\"last\").as_posix()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}